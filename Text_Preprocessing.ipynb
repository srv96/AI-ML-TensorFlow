{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ+IZZhgTTyQy9yPamHDG+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srv96/AI-ML-TensorFlow/blob/main/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cQVsG4rCkKZC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"This is a sentence.\",\n",
        "    \"TensorFlow is a powerful library.\",\n",
        "    \"Python is popular for machine learning.\",\n",
        "    \"This code imports TensorFlow.\"\n",
        "]"
      ],
      "metadata": {
        "id": "eWp5Hr-irFZx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 20_000"
      ],
      "metadata": {
        "id": "vtkFkojkrg27"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layers = tf.keras.layers.TextVectorization(\n",
        "    max_tokens = MAX_VOCAB_SIZE\n",
        "    # standardize = \"lower_and_strip_punctuation\",\n",
        "    # split = \"whitespace\",    DEFAULT VALUES\n",
        "    # output_mode = \"int\",\n",
        ")"
      ],
      "metadata": {
        "id": "LYlkuE0Hrupx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layers.adapt(sentences)"
      ],
      "metadata": {
        "id": "mBq4Fs87sRju"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = vectorization_layers(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r-zKrylsddq",
        "outputId": "e3a061a1-5963-440d-e735-1f177c94dffd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 3  2  5  6  0  0]\n",
            " [ 4  2  5  8 11  0]\n",
            " [ 7  2  9 14 10 12]\n",
            " [ 3 15 13  4  0  0]], shape=(4, 6), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layers.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5GqF27Ds27e",
        "outputId": "30d5d911-ae83-4baf-8993-225971d4a27b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'is',\n",
              " 'this',\n",
              " 'tensorflow',\n",
              " 'a',\n",
              " 'sentence',\n",
              " 'python',\n",
              " 'powerful',\n",
              " 'popular',\n",
              " 'machine',\n",
              " 'library',\n",
              " 'learning',\n",
              " 'imports',\n",
              " 'for',\n",
              " 'code']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = { v:k for k,v in enumerate(vectorization_layers.get_vocabulary()) }\n",
        "print(word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q1mXmZTtF7D",
        "outputId": "0bac30b7-0cf9-4d00-d8fb-533d807fc6c6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, '[UNK]': 1, 'is': 2, 'this': 3, 'tensorflow': 4, 'a': 5, 'sentence': 6, 'python': 7, 'powerful': 8, 'popular': 9, 'machine': 10, 'library': 11, 'learning': 12, 'imports': 13, 'for': 14, 'code': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vactorization_layer_truncate = tf.keras.layers.TextVectorization(\n",
        "    max_tokens = MAX_VOCAB_SIZE,\n",
        "    output_sequence_length = 3\n",
        ")\n",
        "vactorization_layer_truncate.adapt(sentences)\n",
        "sequences = vactorization_layer_truncate(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qD6DE4RtqK2",
        "outputId": "548a51e2-7890-46ec-cc71-65a9c6e9cc46"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 3  2  5]\n",
            " [ 4  2  5]\n",
            " [ 7  2  9]\n",
            " [ 3 15 13]], shape=(4, 3), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layer_pad = tf.keras.layers.TextVectorization(\n",
        "    max_tokens = MAX_VOCAB_SIZE,\n",
        "    output_sequence_length = 10\n",
        ")\n",
        "vectorization_layer_pad.adapt(sentences)\n",
        "sequences = vectorization_layer_pad(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krcRjdSZudVD",
        "outputId": "921622b8-0f19-47d3-e018-2b85d96c0f7e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 3  2  5  6  0  0  0  0  0  0]\n",
            " [ 4  2  5  8 11  0  0  0  0  0]\n",
            " [ 7  2  9 14 10 12  0  0  0  0]\n",
            " [ 3 15 13  4  0  0  0  0  0  0]], shape=(4, 10), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layers_ragged = tf.keras.layers.TextVectorization(\n",
        "    max_tokens = MAX_VOCAB_SIZE,\n",
        "    ragged = True\n",
        ")\n",
        "vectorization_layers_ragged.adapt(sentences)\n",
        "sequences = vectorization_layers_ragged(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7rr5W2huyb6",
        "outputId": "7d22580f-85a4-4c82-d465-9c0ac224f5cc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[3, 2, 5, 6], [4, 2, 5, 8, 11], [7, 2, 9, 14, 10, 12], [3, 15, 13, 4]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded = tf.keras.utils.pad_sequences(sequences.to_list(), maxlen=10)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaGsLyzovGEI",
        "outputId": "97ad505e-baf7-44c4-8580-0961d5de4f33"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  3  2  5  6]\n",
            " [ 0  0  0  0  0  4  2  5  8 11]\n",
            " [ 0  0  0  0  7  2  9 14 10 12]\n",
            " [ 0  0  0  0  0  0  3 15 13  4]]\n"
          ]
        }
      ]
    }
  ]
}